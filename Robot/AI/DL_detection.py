import argparseimport timeimport numpy as npimport cv2from PIL import Imagefrom pycoral.adapters import classifyfrom pycoral.adapters import commonfrom pycoral.utils.dataset import read_label_filefrom pycoral.utils.edgetpu import make_interpreterdef main():	parser = argparse.ArgumentParser(		formatter_class=argparse.ArgumentDefaultsHelpFormatter)	parser.add_argument(		'-m', '--model', required=True, help='File path of .tflite file.')	parser.add_argument(		'-l', '--labels', help='File path of labels file.')	parser.add_argument(		'-k', '--top_k', type=int, default=1,		help='Max number of classification results')	parser.add_argument(		'-t', '--threshold', type=float, default=0.0,		help='Classification score threshold')	parser.add_argument(		'-c', '--count', type=int, default=5,		help='Number of times to run inference')	parser.add_argument(		'-a', '--input_mean', type=float, default=128.0,		help='Mean value for input normalization')	parser.add_argument(		'-s', '--input_std', type=float, default=128.0,		help='STD value for input normalization')	args = parser.parse_args()	labels = read_label_file(args.labels) if args.labels else {}	interpreter = make_interpreter(*args.model.split('@'))	interpreter.allocate_tensors()	# Model must be uint8 quantized	if common.input_details(interpreter, 'dtype') != np.uint8:		raise ValueError('Only support uint8 input type.')	size = common.input_size(interpreter)	params = common.input_details(interpreter, 'quantization_parameters')	scale = params['scales']	zero_point = params['zero_points']	mean = args.input_mean	std = args.input_std	cam_w,cam_h = 224,224	camera = cv2.VideoCapture(0)	ret = camera.set(3,cam_w)	ret = camera.set(4,cam_h)	font = cv2.FONT_HERSHEY_SIMPLEX	bottomLeftCornerOfText = (10,cam_h-10)	fontScale = 1	fontColor = (255,255,255)  # white	boxColor = (0,0,255)   # RED?	boxLineWidth = 1	lineType = 2	while camera.isOpened():		ret,image = camera.read()		if ret == False:			print("can't read from camera")			break		if abs(scale * std - 1) < 1e-5 and abs(mean - zero_point) < 1e-5:			# Input data does not require preprocessing.			image = cv2.resize(image,size)			common.set_input(interpreter, image)		else:			# Input data requires preprocessing			normalized_input = (np.asarray(image) - mean) / (std * scale) + zero_point			np.clip(normalized_input, 0, 255, out=normalized_input)			common.set_input(interpreter, normalized_input.astype(np.uint8))		start = time.perf_counter()		interpreter.invoke()		inference_time = time.perf_counter() - start		fps = 1.0/(inference_time)		classes = classify.get_classes(interpreter, args.top_k, args.threshold)		print('FPS:%.1f\n Panneau:%s'% (fps,labels.get(classes[0].id, classes[0].id)))		#cv2.putText(image,annotate_text,bottomLeftCornerOfText,font,int(fontScale),fontColor,boxColor,int(lineType))		cv2.imshow('Camera', image)		if cv2.waitKey(1) & 0xFF == ord('q'): 			break	camera.release()	cv2.destroyAllWindows()if __name__ == '__main__':	main()